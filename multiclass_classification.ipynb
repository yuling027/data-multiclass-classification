{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We just solved a binary classification problem in the previous challenge. \n",
    "* What about a **multiclass classification task**?\n",
    "\n",
    "üéØ Exercise Objectives:\n",
    "- Write a Neural Network designed for a multiclass classification problem\n",
    "- Observe how this model could easily overfit... !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Create a `Blobs` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö The **`make_blobs`** function from Sklearn [(see documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html) allows you to generate: \n",
    "- an arbitrary number of data sample, argument `n_samples`\n",
    "- an arbitrary number of features per data sample, argument `n_features`\n",
    "- an arbitrary number of categories, argument `centers`\n",
    "- a distance between the categories, argument `cluster_std`\n",
    "\n",
    "üí° There is also the `random_state` argument that allows us to create the data deterministically, in order to reproduce the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "‚ùì Based on the documentation:\n",
    "\n",
    "üëΩ Generate a ***blobs*** dataset with:\n",
    "- 1200 samples\n",
    "- 8 features per sample\n",
    "- 7 categories of data\n",
    "- 8 as the distance between the categories\n",
    "\n",
    "üîÆ Select a `random_state` equal to 1.\n",
    "\n",
    "üìè Print the shape and check that it corresponds to (1200, 8) for `X` and (1200,) for `y` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Use _matplotlib_ to draw a scatterplot of two (arbitrary) dimensions of this blobs dataset. Each dot should be colored with the category it belongs to. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Repeat the operation on other dimensions. You should see visually that the data points are not easily separable ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Encoding the target of a multi-class classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ For the moment, the target `y` is a list of integers,  corresponding to the category of the input data. It looks like `[3, 2, 2, 3, 0, 5, 1, 1, 0, 5, ...]` (in this example, we have 7 categories, from 0 to 6).\n",
    "\n",
    "üßëüèª‚Äçüè´ However, **`for categorical problems in Tensorflow.Keras, the target/output should be encoded`** in the following way:\n",
    "\n",
    "```\n",
    "[\n",
    "[0, 0, 0, 1, 0, 0, 0], \n",
    "[0, 0, 1, 0, 0, 0, 0], \n",
    "[0, 0, 1, 0, 0, 0, 0], \n",
    "[1, 0, 0, 0, 0, 0, 0], \n",
    "[0, 0, 0, 0, 0, 1, 0], \n",
    "[0, 1, 0, 0, 0, 0, 0],\n",
    "[0, 1, 0, 0, 0, 0, 0],\n",
    "[1, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 1],\n",
    "...\n",
    "]\n",
    "```\n",
    "\n",
    "where:\n",
    "* the number of rows is equal to the number of observations\n",
    "* the number of columns is equal to the number of different categories\n",
    "\n",
    "üëâ Each column corresponds to a category. \n",
    "\n",
    "üëâ Each row corresponds to a target, the 1 being the category the input data belongs to.\n",
    "\n",
    "You can view a row as a vector of probabilities.\n",
    "\n",
    "```\n",
    "Example:\n",
    "| Cat 0 | Cat 1 | Cat 2 | Cat 3 | Cat 4 | Cat 5 | Cat 6 |\n",
    "|-------|-------|-------|-------|-------|-------|-------|\n",
    "| 0     | 0     | 0     | 1     | 0     | 0     | 0     |\n",
    "\n",
    "means that for this given row, there is a 100% chance that the row belongs to the Cat 3\n",
    "```\n",
    "\n",
    "--- \n",
    "\n",
    "üí° To transform `y` to categories, use **to_categorical** function from Tensorflow/Keras.\n",
    "\n",
    "\n",
    "<detail>\n",
    "    <summary><i> Is there an analogy between the _to_categorical_ of Tensorflow/Keras and the _OneHotEncoder_ of Scikit-Learn ?</i></summary>\n",
    "    \n",
    "\n",
    "Yes! *to_categorical* works a bit like the OneHotEncoder in Sklearn but instead of encoding a categorical feature, we are now encoding a categorical target.\n",
    "    \n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Encoding the categorical target**:  Print `y`, then apply  *to_categorical* to *`y`* and store the *categorized version of y* into a variable called `y_cat`. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Neural Network for a Multiclass Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Hold-out method**: Split the dataset $X$ and $y_{cat}$ into a _train_ and _test_ set (size: 70/30%)\n",
    "\n",
    "Remark: Please call the variables `X_train`, `X_test`, `y_train`, and `y_test` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Deep Learning, as in any Machine Learning algorithm, your numerical features should be scaled.\n",
    "\n",
    "‚ùì **Scaling**: Fit a Sklearn [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) on the training set and transform both your train set and test set ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Initializing a model**: Complete the following function to build/initialize a model that has: \n",
    "- a first layer with:\n",
    "    - 50 neurons\n",
    "    - the `relu` activation\n",
    "    - the correct input dimension\n",
    "- a output layer:\n",
    "    - designed for a multiclass classification task \n",
    "    - which outputs probabilities of belonging to each class ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "\n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    #############################\n",
    "\n",
    "    pass  # YOUR CODE HERE\n",
    "\n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss='categorical_crossentropy', # different from binary_crossentropy because we have multiple classes\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì  How many parameters (a.k.a. weights) are there in the model ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Fitting the model**: Fit your model on the train data with 50 epochs and plot the history ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Evaluation**:  Evaluate your model on the test set and print the accuracy ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì ü§î Is this a good score? You should compare it to some sort of benchmark value. In this case, what score would a random guess give? Store this baseline score in the `accuracy_baseline` variable. ‚ùì\n",
    "\n",
    "(No need to code for this, just think about how our dataset was created in the first place.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_baseline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('baseline',\n",
    "                         accuracy=accuracy_baseline)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùó üëÄ Wait ... If you get a closer look at the plot of the loss, it seems that the loss was still decreasing after 50 epochs. Why stop it so soon ‚ùì‚ùó\n",
    "\n",
    "‚ùì Let's re-initialize and re-run the model with 1000 epochs this time, and again plot the history. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **When training a model for a longer time...** ‚ùì \n",
    "- What can you say about the new loss? \n",
    "- Once again, evaluate your model on the test set and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* üòÅ The loss computed on the train set seems smaller with 1000 epochs than with 50 epochs. \n",
    "* üòü But the accuracy on the test set is worse with 1000 epochs than with 50 epochs...\n",
    "\n",
    "‚ùì What is this phenomenon called ‚ùì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ü§î What should we do to prevent this from happening? \n",
    "\n",
    "<details>\n",
    "    <summary><i>Possible options</i></summary>\n",
    "    \n",
    "\n",
    "‚ö†Ô∏è To prevent overfitting from happening in Neural Networks, we can - for example:\n",
    "1. Choose a ***reasonable number of epochs*** to prevent the neural network from learning too much from noisy data points\n",
    "2. Create what is called an ***Early Stopping*** criterion, i.e. a way to stop the training earlier than the numbers of epochs set in the _.fit()_ üìÜ cf. ***Deep Learning > Optimizers, Loss, Fitting***\n",
    "\n",
    "</details>    \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Let's visually check when the test loss starts increasing again in practice.  Run the following command and plot the history‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=500,\n",
    "                    batch_size=16,\n",
    "                    verbose=0)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üò± But wait... aren't we cheating if we use the test set? Yes we are. But again, be patient. In ***Deep Learning - Optimizers, Loss, Fitting***, we will use what we call a ***Validation Set*** to avoid this!\n",
    "\n",
    "üßòüèª‚Äç‚ôÄÔ∏è So for now, let's move on to the next questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Evaluating the network**: Plot the values of the loss and accuracy on the <span style=\"color:blue\">train set</span> and on the <span style=\"color:orange\">test set</span>. What can you comment on that ‚ùì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î Why is our Deep Learning model overfitting so easily?\n",
    "\n",
    "üò≥ Think about it, our neural network has to learn ~800 parameters for a simple classification task from a dataset of only 8 features! Besides, we only have ~800 data points in total to fit! The model could almost \"learn\" the exact class of every point in its train set. \n",
    "\n",
    "By contrast, a simple Logistic Regression would have required to learn only 9 parameters to capture the patterns of this blobs dataset! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üòè Deep Learning is fancy, but can clearly be an overkill and unnecessary option for easy Machine Learning tasks!\n",
    "\n",
    "‚≠êÔ∏è It will be extremely useful for:\n",
    "- üì∏ Image Processing\n",
    "- üíπ Time Series\n",
    "- üó£ Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "üèÅ Congratulations!\n",
    "\n",
    "üíæ Don't forget to `git add/commit/push` your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
